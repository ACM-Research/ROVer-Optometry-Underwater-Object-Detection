# ROVer Optometry: Underwater Object Detection
<p align = "center"><img src = https://github.com/ACM-Research/ROVer-Optometry-Underwater-Object-Detection/blob/main/ACM_Research__ROVer_Optometry__Underwater_Object_Detection_-1.png></p>

## Introduction
We will be giving the gift of sight to an ROV! You may ask “okay, well what is an ROV, to begin with?”, well fret not. ROV stands for Remotely Operated Vehicles, they are typically used underwater by many industries like Search and Rescue, Military, Underwater Infrastructure, and much much more.

## Problem Description
The members on this team will learn the basics of image classification and then immediately train a model using convolutional neural networks (CNNs), such as YOLO or MobileNet, to detect certain types of objects under various measures of turbid water. The goal is to demonstrate high-accuracy underwater image classification. If successful, we will witness its effectiveness with a live remotely operated vehicle (ROV) from Robosub.

## Dataset


## Model
<!--We primarily used the TensorFlow 2 Object Detection API to train models. We prioritized speed in our model instances, since the final product would end up processing live input and translating it to game controls. Games require very low input lag, on the order of milliseconds, so a very accurate but slow model fell out of favor as opposed to a generally accurate but fast model. We used SSDMobileNetv2 and YOLOv7, which are excellent at fast object detection. -->

## Training
<!-- The model was trained on Google Colaboratory, since it provided a Python environment with usable GPUs for training. -->

## Our Solution


## Contributors
- Aditya Kulkarni
- Farman Ali
- Parisa Nawar
- Sruti Karthikeyan
- Aarian Ahsan (Research Lead)
- Dr. Yonas Tadesse (Advisor)
